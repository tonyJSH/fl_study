{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aee3248-c1f1-4138-adcc-4ccbe6aed102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 20:55:45.707413: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-10 20:55:45.805024: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-10 20:55:45.829641: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-10 20:55:46.202309: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.4/lib64\n",
      "2023-08-10 20:55:46.202364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.4/lib64\n",
      "2023-08-10 20:55:46.202369: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import os\n",
    "# Tensorflow 로그 출력 줄이기\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "# 동시 9명 연합학습을 위해 cpu 사용\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d79c9-23aa-4854-b33a-52d96e7e08f8",
   "metadata": {},
   "source": [
    "## TensorFlow 연합학습 클라이언트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f64e0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 20:55:47.616719: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-08-10 20:55:47.616799: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: dilab248\n",
      "2023-08-10 20:55:47.616813: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: dilab248\n",
      "2023-08-10 20:55:47.616963: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-08-10 20:55:47.617022: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.199.2\n",
      "2023-08-10 20:55:47.618589: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO flwr 2023-08-10 20:55:47,716 | grpc.py:50 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-08-10 20:55:47,720 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-08-10 20:55:47,722 | connection.py:39 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.5211 - accuracy: 0.8491 - 1s/epoch - 4ms/step\n",
      "53/53 - 0s - loss: 0.1722 - accuracy: 0.9550 - 325ms/epoch - 6ms/step\n",
      "313/313 - 1s - loss: 0.2619 - accuracy: 0.9238 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.1174 - accuracy: 0.9661 - 119ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.2048 - accuracy: 0.9419 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0911 - accuracy: 0.9724 - 114ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1742 - accuracy: 0.9503 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0786 - accuracy: 0.9778 - 115ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1536 - accuracy: 0.9552 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0689 - accuracy: 0.9793 - 104ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1380 - accuracy: 0.9591 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0613 - accuracy: 0.9820 - 108ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1251 - accuracy: 0.9637 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0567 - accuracy: 0.9829 - 112ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1160 - accuracy: 0.9659 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0529 - accuracy: 0.9841 - 132ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1055 - accuracy: 0.9695 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0497 - accuracy: 0.9850 - 95ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.0980 - accuracy: 0.9695 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0458 - accuracy: 0.9856 - 117ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-08-10 20:56:02,237 | connection.py:113 | gRPC channel closed\n",
      "INFO flwr 2023-08-10 20:56:02,239 | app.py:185 | Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow 로그 출력 줄이기\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model_fl = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_fl.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 하나의 리스트를 n개로 분할하는 함수 정의\n",
    "def list_split(arr, n):\n",
    "    num = math.ceil(len(arr) / n)\n",
    "    return [arr[i: i + num] for i in range(0, len(arr), num)]\n",
    "\n",
    "x_train_list, y_train_list, x_val_list, y_val_list = map(list_split, (x_train, y_train, x_test, y_test), (3, 3, 3, 3))\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, x_train, y_train, x_val, y_val):\n",
    "        self.model = model\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_val, self.y_val = x_val, y_val\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights() # 모델의 파라미터 반환\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters) # 서버에서 받은 parameters 모델 적용\n",
    "        self.model.fit(self.x_train, self.y_train, batch_size=64, epochs=1, verbose=2) # 모델 학습\n",
    "        return self.model.get_weights(), len(self.x_train), {} # 필수 반환\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters) # 서버에서 받은 parameters 모델 적용\n",
    "        loss, acc = self.model.evaluate(self.x_val, self.y_val, batch_size=64, verbose=2)\n",
    "        return loss, len(self.x_val), {\"accuracy\": acc} # 필수 반환\n",
    "\n",
    "client_num = 2\n",
    "flwr_client = FlowerClient(model_fl, x_train_list[client_num], y_train_list[client_num], x_val_list[client_num], y_val_list[client_num])\n",
    "fl.client.start_numpy_client(server_address=\"127.0.0.1:8080\", client=flwr_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_study",
   "language": "python",
   "name": "fl_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
