{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2f6694-d0f2-43f0-b3ab-d8d1ab52e084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 20:55:43.093858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-10 20:55:43.192088: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-10 20:55:43.216633: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-10 20:55:43.596190: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.4/lib64\n",
      "2023-08-10 20:55:43.596239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.4/lib64\n",
      "2023-08-10 20:55:43.596260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import os\n",
    "# Tensorflow 로그 출력 줄이기\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "# 동시 9명 연합학습을 위해 cpu 사용\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51799f3-f37b-488b-9606-aa1cfeaa16e0",
   "metadata": {},
   "source": [
    "## TensorFlow 연합학습 클라이언트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7470f3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 20:55:45.066212: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-08-10 20:55:45.066299: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: dilab248\n",
      "2023-08-10 20:55:45.066314: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: dilab248\n",
      "2023-08-10 20:55:45.066471: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-08-10 20:55:45.066534: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.199.2\n",
      "2023-08-10 20:55:45.067621: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO flwr 2023-08-10 20:55:45,170 | grpc.py:50 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-08-10 20:55:45,174 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-08-10 20:55:45,176 | connection.py:39 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.5340 - accuracy: 0.8454 - 1s/epoch - 4ms/step\n",
      "53/53 - 0s - loss: 0.2787 - accuracy: 0.9205 - 314ms/epoch - 6ms/step\n",
      "313/313 - 1s - loss: 0.2721 - accuracy: 0.9208 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.2097 - accuracy: 0.9376 - 118ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.2136 - accuracy: 0.9380 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.1762 - accuracy: 0.9487 - 117ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1797 - accuracy: 0.9469 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.1537 - accuracy: 0.9529 - 125ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1576 - accuracy: 0.9538 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.1358 - accuracy: 0.9589 - 116ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1421 - accuracy: 0.9591 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.1261 - accuracy: 0.9595 - 143ms/epoch - 3ms/step\n",
      "313/313 - 1s - loss: 0.1261 - accuracy: 0.9608 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.1177 - accuracy: 0.9616 - 127ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1137 - accuracy: 0.9661 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.1088 - accuracy: 0.9688 - 122ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.1080 - accuracy: 0.9674 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.1055 - accuracy: 0.9682 - 125ms/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.0979 - accuracy: 0.9713 - 1s/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0982 - accuracy: 0.9700 - 101ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-08-10 20:56:02,240 | connection.py:113 | gRPC channel closed\n",
      "INFO flwr 2023-08-10 20:56:02,241 | app.py:185 | Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow 로그 출력 줄이기\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model_fl = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_fl.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 하나의 리스트를 n개로 분할하는 함수 정의\n",
    "def list_split(arr, n):\n",
    "    num = math.ceil(len(arr) / n)\n",
    "    return [arr[i: i + num] for i in range(0, len(arr), num)]\n",
    "\n",
    "x_train_list, y_train_list, x_val_list, y_val_list = map(list_split, (x_train, y_train, x_test, y_test), (3, 3, 3, 3))\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, x_train, y_train, x_val, y_val):\n",
    "        self.model = model\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_val, self.y_val = x_val, y_val\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights() # 모델의 파라미터 반환\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters) # 서버에서 받은 parameters 모델 적용\n",
    "        self.model.fit(self.x_train, self.y_train, batch_size=64, epochs=1, verbose=2) # 모델 학습\n",
    "        return self.model.get_weights(), len(self.x_train), {} # 필수 반환\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters) # 서버에서 받은 parameters 모델 적용\n",
    "        loss, acc = self.model.evaluate(self.x_val, self.y_val, batch_size=64, verbose=2)\n",
    "        return loss, len(self.x_val), {\"accuracy\": acc} # 필수 반환\n",
    "\n",
    "client_num = 1\n",
    "flwr_client = FlowerClient(model_fl, x_train_list[client_num], y_train_list[client_num], x_val_list[client_num], y_val_list[client_num])\n",
    "fl.client.start_numpy_client(server_address=\"127.0.0.1:8080\", client=flwr_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_study",
   "language": "python",
   "name": "fl_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
