{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "770692a9",
   "metadata": {},
   "source": [
    "# MNIST 데이터셋을 활용한 연합학습\n",
    "- pytorch 모델의 연합학습 코드 이해\n",
    "- 클라이언트의 데이터 분포가 균등하지 않을 때(non-iid)상황 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7938b0b1",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfaf203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 17:08:13.363727: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-23 17:08:13.472446: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-23 17:08:13.496416: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-23 17:08:13.884336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-08-23 17:08:13.884411: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-08-23 17:08:13.884415: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "import flwr as fl\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a89ca67",
   "metadata": {},
   "source": [
    "### (주의 사항) 수강생 모두가 동일한 GPU를 사용하면 속도가 매우 느려지거나 오류가 발생할 수 있음\n",
    "### 아래와 같이 각 조는 개별 GPU를 사용하기로 함\n",
    "- 1조 : cuda:1\n",
    "- 2조 : cuda:2\n",
    "- 3조 : cuda:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11408c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.12.1+cu113  Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "''' 딥러닝 모델을 설계할 때 활용하는 장비 확인 '''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda:0') # 해당 조의 GPU 번호로 변경 ex) 1조 : cuda:1\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b637f8",
   "metadata": {},
   "source": [
    "## MNIST 데이터셋\n",
    "- 0부터 9까지의 숫자를 손글씨로 쓴 이미지들로 구성\n",
    "- 각 이미지는 28x28 픽셀 크기의 흑백 이미지로 총 784(=28x28)개의 픽셀로 이루어져 있음\n",
    "- 머신 러닝 분야에서 가장 많이 사용되는 벤치마크 데이터셋 중 하나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd402b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() # 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환\n",
    "    ])\n",
    ")\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() # 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환\n",
    "    ])\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "# train_loader, test_loader 생성\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412fb65-f133-4acf-804b-a56f69e3cb79",
   "metadata": {},
   "source": [
    "## Pytorch 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f2ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dense2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "torch_model = MLP().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(torch_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6489f2-2c85-42a0-8edb-543eb95ea522",
   "metadata": {},
   "source": [
    "## Pytorch 모델 학습 및 검증 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b15a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def train(model, epoch, train_loader, optimizer, log_interval, loss_fn):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                                                    epoch, batch_idx * len(image), \n",
    "                                                    len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                                                    loss.item()))\n",
    "            \n",
    "''' 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def evaluate(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += loss_fn(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c1c79d",
   "metadata": {},
   "source": [
    "## 중앙 집중식 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca35fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tTrain Loss: 2.302057\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tTrain Loss: 1.588729\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tTrain Loss: 1.597936\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 1.5692, \tTest Accuracy: 91.89 % \n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tTrain Loss: 1.534423\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tTrain Loss: 1.552608\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tTrain Loss: 1.569575\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 1.5493, \tTest Accuracy: 93.72 % \n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tTrain Loss: 1.514712\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tTrain Loss: 1.540715\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tTrain Loss: 1.532815\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 1.5376, \tTest Accuracy: 94.51 % \n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tTrain Loss: 1.489792\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tTrain Loss: 1.532976\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tTrain Loss: 1.522904\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 1.5299, \tTest Accuracy: 95.20 % \n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tTrain Loss: 1.494381\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tTrain Loss: 1.531907\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tTrain Loss: 1.511984\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 1.5250, \tTest Accuracy: 95.63 % \n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tTrain Loss: 1.497726\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tTrain Loss: 1.512463\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tTrain Loss: 1.504512\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 1.5202, \tTest Accuracy: 96.11 % \n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tTrain Loss: 1.492874\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tTrain Loss: 1.520558\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tTrain Loss: 1.505175\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 1.5175, \tTest Accuracy: 96.24 % \n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tTrain Loss: 1.481933\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tTrain Loss: 1.500238\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tTrain Loss: 1.497475\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 1.5141, \tTest Accuracy: 96.62 % \n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tTrain Loss: 1.483736\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tTrain Loss: 1.507342\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tTrain Loss: 1.497797\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 1.5122, \tTest Accuracy: 96.78 % \n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tTrain Loss: 1.483959\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tTrain Loss: 1.495866\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tTrain Loss: 1.507334\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 1.5101, \tTest Accuracy: 96.90 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' MLP 학습 실행하며 Train, Test set의 Loss 및 Test set Accuracy 확인하기 '''\n",
    "EPOCHS = 10\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(torch_model, epoch, train_loader, optimizer, 200, criterion)\n",
    "    test_loss, test_accuracy = evaluate(torch_model, test_loader, criterion)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb57bad",
   "metadata": {},
   "source": [
    "## 연합학습을 위한 데이터 분할\n",
    "- 각 클라이언트는 서로 다른 데이터를 가지고 있어야 하기에 데이터를 클라이어트의 수 만큼 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447e8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 리스트를 n개로 분할하는 함수 정의\n",
    "def list_split(arr, n):\n",
    "    num = math.trunc(len(arr) / n)\n",
    "    return [arr[i: i + num] for i in range(0, len(arr), num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94bb8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클라이언트가 학습하기위한 데이터 분할\n",
    "# 해당 예제에서는 3개의 클라이언트를 연합학습\n",
    "num_clients = 3\n",
    "x_train_list, y_train_list, x_val_list, y_val_list = map(list_split, (train_set.data, train_set.targets, test_set.data, test_set.targets), (num_clients, num_clients, num_clients, num_clients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5bd479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e8adc",
   "metadata": {},
   "source": [
    "## 커스텀 데이터 셋 정의\n",
    "- 연합학습을 위해 분할된 데이터는 tensor이기 때문에 이를 다시 Dataloader 클래스로 정의가 필요함\n",
    "- pytorch에서 제공하는 DataLoader를 사용하기 위해선 아래와 같은 데이터 셋 클래스가 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de35808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transforms=None):\n",
    "        self.X = images\n",
    "        self.y = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = self.X[i, :]\n",
    "        data = np.array(data).astype(np.float32).reshape(1, 28, 28)\n",
    "        return (data, self.y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e3e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "train_dataset_n = MnistDataSet(x_train_list[num], y_train_list[num])\n",
    "test_dataset_n = MnistDataSet(x_val_list[num], y_val_list[num])\n",
    "BATCH_SIZE = 128\n",
    "train_loader_n = DataLoader(train_dataset_n, batch_size=BATCH_SIZE)\n",
    "test_loader_n = DataLoader(test_dataset_n, batch_size=BATCH_SIZE)\n",
    "\n",
    "torch_model_cen = MLP().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer_cen = torch.optim.Adam(torch_model_cen.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ce5c3",
   "metadata": {},
   "source": [
    "## 분할된 데이터의 중앙 집중식 학습\n",
    "- 데이터를 1/3로 분할하여 성능이 감소됨을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15151a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 2.383274\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 2.0998, \tTest Accuracy: 43.68 % \n",
      "\n",
      "Train Epoch: 2 [0/20000 (0%)]\tTrain Loss: 2.038481\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 1.9555, \tTest Accuracy: 57.61 % \n",
      "\n",
      "Train Epoch: 3 [0/20000 (0%)]\tTrain Loss: 1.851315\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 1.8936, \tTest Accuracy: 64.33 % \n",
      "\n",
      "Train Epoch: 4 [0/20000 (0%)]\tTrain Loss: 1.725895\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 1.8264, \tTest Accuracy: 70.36 % \n",
      "\n",
      "Train Epoch: 5 [0/20000 (0%)]\tTrain Loss: 1.726390\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 1.8227, \tTest Accuracy: 71.50 % \n",
      "\n",
      "Train Epoch: 6 [0/20000 (0%)]\tTrain Loss: 1.703258\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 1.8410, \tTest Accuracy: 68.83 % \n",
      "\n",
      "Train Epoch: 7 [0/20000 (0%)]\tTrain Loss: 1.745964\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 1.8284, \tTest Accuracy: 70.87 % \n",
      "\n",
      "Train Epoch: 8 [0/20000 (0%)]\tTrain Loss: 1.718960\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 1.8441, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 9 [0/20000 (0%)]\tTrain Loss: 1.744913\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 1.8360, \tTest Accuracy: 69.40 % \n",
      "\n",
      "Train Epoch: 10 [0/20000 (0%)]\tTrain Loss: 1.742174\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 1.8293, \tTest Accuracy: 70.78 % \n",
      "\n",
      "Train Epoch: 11 [0/20000 (0%)]\tTrain Loss: 1.734399\n",
      "\n",
      "[EPOCH: 11], \tTest Loss: 1.8464, \tTest Accuracy: 69.04 % \n",
      "\n",
      "Train Epoch: 12 [0/20000 (0%)]\tTrain Loss: 1.709362\n",
      "\n",
      "[EPOCH: 12], \tTest Loss: 1.8148, \tTest Accuracy: 72.25 % \n",
      "\n",
      "Train Epoch: 13 [0/20000 (0%)]\tTrain Loss: 1.734473\n",
      "\n",
      "[EPOCH: 13], \tTest Loss: 1.7732, \tTest Accuracy: 76.33 % \n",
      "\n",
      "Train Epoch: 14 [0/20000 (0%)]\tTrain Loss: 1.684421\n",
      "\n",
      "[EPOCH: 14], \tTest Loss: 1.7567, \tTest Accuracy: 78.01 % \n",
      "\n",
      "Train Epoch: 15 [0/20000 (0%)]\tTrain Loss: 1.656463\n",
      "\n",
      "[EPOCH: 15], \tTest Loss: 1.7703, \tTest Accuracy: 76.72 % \n",
      "\n",
      "Train Epoch: 16 [0/20000 (0%)]\tTrain Loss: 1.648610\n",
      "\n",
      "[EPOCH: 16], \tTest Loss: 1.7444, \tTest Accuracy: 79.27 % \n",
      "\n",
      "Train Epoch: 17 [0/20000 (0%)]\tTrain Loss: 1.633026\n",
      "\n",
      "[EPOCH: 17], \tTest Loss: 1.7345, \tTest Accuracy: 80.23 % \n",
      "\n",
      "Train Epoch: 18 [0/20000 (0%)]\tTrain Loss: 1.635459\n",
      "\n",
      "[EPOCH: 18], \tTest Loss: 1.7479, \tTest Accuracy: 78.22 % \n",
      "\n",
      "Train Epoch: 19 [0/20000 (0%)]\tTrain Loss: 1.628718\n",
      "\n",
      "[EPOCH: 19], \tTest Loss: 1.7232, \tTest Accuracy: 80.68 % \n",
      "\n",
      "Train Epoch: 20 [0/20000 (0%)]\tTrain Loss: 1.609585\n",
      "\n",
      "[EPOCH: 20], \tTest Loss: 1.7302, \tTest Accuracy: 80.65 % \n",
      "\n",
      "Train Epoch: 21 [0/20000 (0%)]\tTrain Loss: 1.601776\n",
      "\n",
      "[EPOCH: 21], \tTest Loss: 1.7259, \tTest Accuracy: 81.13 % \n",
      "\n",
      "Train Epoch: 22 [0/20000 (0%)]\tTrain Loss: 1.594023\n",
      "\n",
      "[EPOCH: 22], \tTest Loss: 1.7321, \tTest Accuracy: 80.56 % \n",
      "\n",
      "Train Epoch: 23 [0/20000 (0%)]\tTrain Loss: 1.601568\n",
      "\n",
      "[EPOCH: 23], \tTest Loss: 1.7309, \tTest Accuracy: 80.59 % \n",
      "\n",
      "Train Epoch: 24 [0/20000 (0%)]\tTrain Loss: 1.602162\n",
      "\n",
      "[EPOCH: 24], \tTest Loss: 1.7230, \tTest Accuracy: 81.40 % \n",
      "\n",
      "Train Epoch: 25 [0/20000 (0%)]\tTrain Loss: 1.601845\n",
      "\n",
      "[EPOCH: 25], \tTest Loss: 1.7347, \tTest Accuracy: 80.26 % \n",
      "\n",
      "Train Epoch: 26 [0/20000 (0%)]\tTrain Loss: 1.593963\n",
      "\n",
      "[EPOCH: 26], \tTest Loss: 1.7475, \tTest Accuracy: 79.00 % \n",
      "\n",
      "Train Epoch: 27 [0/20000 (0%)]\tTrain Loss: 1.664273\n",
      "\n",
      "[EPOCH: 27], \tTest Loss: 1.7201, \tTest Accuracy: 81.70 % \n",
      "\n",
      "Train Epoch: 28 [0/20000 (0%)]\tTrain Loss: 1.601776\n",
      "\n",
      "[EPOCH: 28], \tTest Loss: 1.7337, \tTest Accuracy: 80.35 % \n",
      "\n",
      "Train Epoch: 29 [0/20000 (0%)]\tTrain Loss: 1.609577\n",
      "\n",
      "[EPOCH: 29], \tTest Loss: 1.7365, \tTest Accuracy: 80.05 % \n",
      "\n",
      "Train Epoch: 30 [0/20000 (0%)]\tTrain Loss: 1.625147\n",
      "\n",
      "[EPOCH: 30], \tTest Loss: 1.7131, \tTest Accuracy: 82.42 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' MLP 학습 실행하며 Train, Test set의 Loss 및 Test set Accuracy 확인하기 '''\n",
    "EPOCHS = 30\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(torch_model_cen, epoch, train_loader_n, optimizer_cen, 200, criterion)\n",
    "    test_loss, test_accuracy = evaluate(torch_model_cen, test_loader_n, criterion)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c7e590-0a30-4bec-a5d5-bc3520243a69",
   "metadata": {},
   "source": [
    "## Pytorch 모델의 FlowerClient 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "082c133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, tarinloader, testloader, opt, loss_fn):\n",
    "        self.model = model\n",
    "        self.train_loader = tarinloader\n",
    "        self.test_loader = testloader\n",
    "        self.optimizer = opt\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters): # pytorch 모델에 파라미터를 적용하는 코드가 복잡하여 함수로 정의\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters) # 위에서 정의한 set_parameters함수를 사용\n",
    "        train(self.model, 1, self.train_loader, self.optimizer, 200, self.loss_fn)\n",
    "        return self.get_parameters(config={}), len(self.train_loader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = evaluate(self.model, self.test_loader, self.loss_fn)\n",
    "        return loss, len(self.test_loader.dataset), {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73982066-d506-4dea-a8fa-e011b35cadfa",
   "metadata": {},
   "source": [
    "## 연합학습 코드\n",
    "- 앞서 정의한 FlowerClient를 fl.client.start_numpy_client 함수를 통해 클라이언트 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170ab41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fl = MLP().to(DEVICE)\n",
    "criterion_fl = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer_fl = torch.optim.Adam(model_fl.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b1e49-7d00-43e9-b6d0-32b72acccf80",
   "metadata": {},
   "source": [
    "### 같은 폴더에 있는 server 파일의 \"1번\" 코드를 먼저 실행하고 아래 셀과 clinet1, clinet2 파일을 실행\n",
    "### client1, client2 파일의 DEVICE를 해당 조의 GPU 번호로 변경해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54949906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-08-23 17:13:53,689 | grpc.py:50 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-08-23 17:13:53,697 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-08-23 17:13:53,699 | connection.py:39 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 2.256194\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.888608\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.647757\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.578306\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.539276\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.534175\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.554655\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.513684\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.501544\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.516202\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.500203\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.500197\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.515838\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.492401\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.499557\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.500213\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.500425\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.500293\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.507884\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.500213\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.508026\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.484589\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.492401\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.484588\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.492324\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.500019\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.492236\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.497093\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.484586\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.492401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-08-23 17:14:20,162 | connection.py:113 | gRPC channel closed\n",
      "INFO flwr 2023-08-23 17:14:20,162 | app.py:185 | Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "client_num = 0\n",
    "\n",
    "train_dataset_fl = MnistDataSet(x_train_list[client_num], y_train_list[client_num])\n",
    "test_dataset_fl = MnistDataSet(x_val_list[client_num], y_val_list[client_num])\n",
    "BATCH_SIZE = 128\n",
    "train_loader_fl = DataLoader(train_dataset_fl, batch_size=BATCH_SIZE)\n",
    "test_loader_fl = DataLoader(test_dataset_fl, batch_size=BATCH_SIZE)\n",
    "\n",
    "flwr_client = FlowerClient(model_fl, train_loader_fl, test_loader_fl, optimizer_fl, criterion_fl)\n",
    "\n",
    "fl.client.start_numpy_client(server_address=\"127.0.0.1:8080\", client=flwr_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aeb470",
   "metadata": {},
   "source": [
    "## NON-IID상황의 연합학습\n",
    "- IID(Independent Identically Distributed) : 데이터의 클래스 분포가 균등한 상황\n",
    "- NON-IID(NON-Independent Identically Distributed) : 데이터의 클래스 분포가 균등하지 않고 특정 클래스의 개수가 현저히 적거나 많은 상황"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e137a73",
   "metadata": {},
   "source": [
    "## NON-IID 상황을 가정하기 위해 데이터 클래스 개수와 분포 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b600e1",
   "metadata": {},
   "source": [
    "### 특정 값의 텐서만 가져오는 코드 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7ca05d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False,  True, False, False,  True, False, False])\n",
      "tensor([False,  True, False, False,  True, False, False,  True, False])\n",
      "tensor([1, 1, 1])\n",
      "tensor([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "ts = torch.tensor([1,2,3,1,2,3,1,2,3])\n",
    "c1 = ts == 1\n",
    "c2 = ts == 2\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(ts[c1])\n",
    "print(ts[c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d0cc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 별로 다른 분포를 갖게 분할하는 코드\n",
    "# 코드가 복잡하지만 위 셀의 원리로 분할함 (완벽히 이해할 필요 없음)\n",
    "def non_iid_split(client_num:int, ratio:float, dataset):\n",
    "    client_x = [[] for i in range(client_num)]\n",
    "    client_y = [[] for i in range(client_num)]\n",
    "    for i in range(client_num):\n",
    "        data = dataset.data[dataset.targets == i]\n",
    "        targets = dataset.targets[dataset.targets == i]\n",
    "        ratio_num = math.ceil(ratio * len(targets))\n",
    "        client_x[i].append(data[:ratio_num])\n",
    "        client_y[i].append(targets[:ratio_num])\n",
    "        if len(data[ratio_num:]) / (client_num - 1) != 0:\n",
    "            data_tail = list_split(data[ratio_num:], client_num -1)\n",
    "            targets_tail = list_split(targets[ratio_num:], client_num -1)\n",
    "            for l in [n for n in range(client_num) if n != i]:\n",
    "                client_x[l].append(data_tail.pop(0))\n",
    "                client_y[l].append(targets_tail.pop(0))\n",
    "    \n",
    "    return [torch.concat(t, dim=0) for t in client_x], [torch.concat(t, dim=0) for t in client_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ce764",
   "metadata": {},
   "source": [
    "### 텍스트 파일을 읽어 ratio값 저장\n",
    "- 다른 클라이언트의 ratio 변수를 한번에 변경하기 위해 텍스트 파일로 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58fe173f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# ratio가 0.9이면 특정 클래스의 90%가 한 클라이언트에 있도록 함\n",
    "num_clients = 10\n",
    "with open('ratio.txt', 'r') as f:\n",
    "    r = float(f.readline())\n",
    "    ratio = r\n",
    "print(ratio)\n",
    "x_train_list, y_train_list = non_iid_split(num_clients, ratio, train_set)\n",
    "x_test_list, y_test_list = non_iid_split(num_clients, ratio, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a12188",
   "metadata": {},
   "source": [
    "### 클라이언트 별 분포 확인\n",
    "### 각 클라이언트가 색으로 구분됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ea49b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train_list, bins=10)\n",
    "plt.xlabel('label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1ab206",
   "metadata": {},
   "source": [
    "### 같은 폴더에 있는 server 파일의 \"2번\" 코드를 먼저 실행하고 아래 셀을 실행\n",
    "### 이후 아래 설명과 같이 터미널에서 명령어 실행\n",
    "### client_noniid.py파일의 DEVICE를 해당 조의 GPU 번호로 변경해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "313e9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 같은 폴더에 있는 server 파일의 \"1번\" 코드를 먼저 실행하고 아래 셀과 clinet1, clinet2 파일을 실행\n",
    "### client1, client2 파일의 DEVICE를 해당 조의 GPU 번호로 변경해야 함\n",
    "model_fl = MLP().to(DEVICE)\n",
    "criterion_fl = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer_fl = torch.optim.Adam(model_fl.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09d7482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-08-23 17:16:58,399 | grpc.py:50 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-08-23 17:16:58,406 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-08-23 17:16:58,409 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flwr 2023-08-23 17:16:58,412 | connection.py:39 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.454183\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.334679\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.435224\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.443129\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.734187\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.455455\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.458067\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.036931\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.783564\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.458583\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.458689\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.339019\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.516295\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.458290\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.427006\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.562360\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.455928\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.223918\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.627522\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.921485\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.684696\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.181106\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.632167\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.264860\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.609978\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.409143\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.744652\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 2.245193\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.945548\n",
      "Train Epoch: 1 [0/5923 (0%)]\tTrain Loss: 1.697676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-08-23 17:17:25,047 | connection.py:113 | gRPC channel closed\n",
      "INFO flwr 2023-08-23 17:17:25,048 | app.py:185 | Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "client_num = 0\n",
    "\n",
    "train_dataset_fl = MnistDataSet(x_train_list[client_num], y_train_list[client_num])\n",
    "test_dataset_fl = MnistDataSet(x_test_list[client_num], y_test_list[client_num])\n",
    "BATCH_SIZE = 128\n",
    "train_loader_fl = DataLoader(train_dataset_fl, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader_fl = DataLoader(test_dataset_fl, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "flwr_client = FlowerClient(model_fl, train_loader_fl, test_loader_fl, optimizer_fl, criterion_fl)\n",
    "\n",
    "fl.client.start_numpy_client(server_address=\"127.0.0.1:8080\", client=flwr_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74e1c4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.34"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = evaluate(model_fl, test_loader, criterion_fl)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ffa1f",
   "metadata": {},
   "source": [
    "## 아래 명령어를 주피터 터미널에서 실행\n",
    "1. conda activate 를 통해 가상환경에 진입\n",
    "2. cd 명령어를 통해 MNIST_flower 폴더에 진입\n",
    "3. 아래 명령어 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c24ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "python client_noniid.py 1 & python client_noniid.py 2 & python client_noniid.py 3 & python client_noniid.py 4 & python client_noniid.py 5 & python client_noniid.py 6 & python client_noniid.py 7 & python client_noniid.py 8 & python client_noniid.py 9 &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_study",
   "language": "python",
   "name": "ai_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
