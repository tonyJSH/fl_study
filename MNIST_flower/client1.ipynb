{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9dad70f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-08-25 11:36:31,197 | grpc.py:50 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-08-25 11:36:31,202 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-08-25 11:36:31,204 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flwr 2023-08-25 11:36:31,205 | connection.py:39 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.12.1+cu113  Device: cuda:0\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 2.384142\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.992949\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.677490\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.640358\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.576753\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.580506\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.557527\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.610026\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.593388\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.558027\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.539342\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.522570\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.542152\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.531485\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.554901\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.559279\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.536617\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.518011\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.500419\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.547609\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.539274\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.524220\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.500270\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.525119\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.523652\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.523650\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.520867\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.525538\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.523324\n",
      "Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 1.500294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-08-25 11:36:54,630 | connection.py:113 | gRPC channel closed\n",
      "INFO flwr 2023-08-25 11:36:54,631 | app.py:185 | Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "import flwr as fl\n",
    "import math\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda:0') # 해당 조의 GPU 번호로 변경 ex) 1조 : cuda:1\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dense2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "def train(model, epoch, train_loader, optimizer, log_interval, loss_fn):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                                                    epoch, batch_idx * len(image), \n",
    "                                                    len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                                                    loss.item()))\n",
    "            \n",
    "def evaluate(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += loss_fn(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() # 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환\n",
    "    ])\n",
    ")\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() # 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환\n",
    "    ])\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def list_split(arr, n):\n",
    "    num = math.ceil(len(arr) / n)\n",
    "    return [arr[i: i + num] for i in range(0, len(arr), num)]\n",
    "\n",
    "num_clients = 3\n",
    "x_train_list, y_train_list, x_val_list, y_val_list = map(list_split, (train_set.data, train_set.targets, test_set.data, test_set.targets), (num_clients, num_clients, num_clients, num_clients))\n",
    "\n",
    "\n",
    "class MnistDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transforms=None):\n",
    "        self.X = images\n",
    "        self.y = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = self.X[i, :]\n",
    "        data = np.array(data).astype(np.float32).reshape(1, 28, 28)\n",
    "        return (data, self.y[i])\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, tarinloader, testloader, opt, loss_fn):\n",
    "        self.model = model\n",
    "        self.train_loader = tarinloader\n",
    "        self.test_loader = testloader\n",
    "        self.optimizer = opt\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters): # pytorch 모델에 파라미터를 적용하는 코드가 복잡하여 함수로 정의\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters) # 위에서 정의한 set_parameters함수를 사\n",
    "        train(self.model, 1, self.train_loader, self.optimizer, 200, self.loss_fn)\n",
    "        return self.get_parameters(config={}), len(self.train_loader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = evaluate(self.model, self.test_loader, self.loss_fn)\n",
    "        return loss, len(self.test_loader.dataset), {\"accuracy\": accuracy}\n",
    "    \n",
    "model_fl = MLP().to(DEVICE)\n",
    "criterion_fl = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer_fl = torch.optim.Adam(model_fl.parameters())\n",
    "\n",
    "client_num = 1\n",
    "\n",
    "train_dataset_fl = MnistDataSet(x_train_list[client_num], y_train_list[client_num])\n",
    "test_dataset_fl = MnistDataSet(x_val_list[client_num], y_val_list[client_num])\n",
    "BATCH_SIZE = 128\n",
    "train_loader_fl = DataLoader(train_dataset_fl, batch_size=BATCH_SIZE)\n",
    "test_loader_fl = DataLoader(test_dataset_fl, batch_size=BATCH_SIZE)\n",
    "\n",
    "flwr_client = FlowerClient(model_fl, train_loader_fl, test_loader_fl, optimizer_fl, criterion_fl)\n",
    "\n",
    "fl.client.start_numpy_client(server_address=\"127.0.0.1:8080\", client=flwr_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_study",
   "language": "python",
   "name": "fl_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
